# মেশিন লার্নিং এবং এআই কোর্স

এই রিপোজিটরিটি একটি **ইন্ডিপেন্ডেন্ট কোর্স** হিসেবে সাজানো হয়েছে, যেখানে Sebastian Raschka-এর বই **_“Machine Learning Q and A: 30 Essential Questions and Answers on Machine Learning and AI”_**–এর আউটলাইন অনুসরণ করে ধাপে ধাপে টপিকগুলো কভার করা হবে।  

প্রতিটি অধ্যায়ে থাকবে—**নোটস**, **পাইথন কোড উদাহরণ**, **এক্সারসাইজ**, এবং **সলিউশন**। সমস্ত কন্টেন্ট GitHub-এ আপলোড করা হবে এবং ফোল্ডার স্ট্রাকচার বইয়ের **Part** ও **Chapter** অনুযায়ী সাজানো থাকবে।

---

## কোর্সের উদ্দেশ্য
- মেশিন লার্নিং এবং এআই-এর **বেসিক থেকে অ্যাডভান্সড** টপিক কভার করা  
- প্রতিটি অধ্যায়ে থাকবে: **থিওরি + কোড (Python) + এক্সারসাইজ**  
- শিক্ষার্থীদের জন্য **সহজবোধ্য** এবং **প্র্যাকটিক্যাল** অ্যাপ্রোচ  
- **Open Source**: যে কেউ কন্ট্রিবিউট করতে পারবেন  

---

## রিপোজিটরি ফোল্ডার স্ট্রাকচার
রিপোজিটরির ফোল্ডারগুলো বইয়ের পার্ট অনুযায়ী সাজানো হবে:

- **Part-I-Neural-Networks-and-Deep-Learning/** — Chapter 1–10  
- **Part-II-Computer-Vision/** — Chapter 11–13  
- **Part-III-Natural-Language-Processing/** — Chapter 14–19  
- **Part-IV-Predictive-Performance-and-Model-Evaluation/** — Chapter 20–30  
- **Appendix/** — এক্সারসাইজের উত্তর (Solutions)  
- **Resources/** — অতিরিক্ত রেফারেন্স, ডেটাসেট, টুলস  
- **docs/** — বাড়তি ডকুমেন্টেশন  

প্রতিটি পার্টের ভিতরে চ্যাপ্টার অনুযায়ী সাব-ফোল্ডার থাকবে, যেমন:

- `Chapter-1/`
  - `notes.md`
  - `code.ipynb`
  - `exercises.md`
  - `solutions.md` (ঐচ্ছিক)

---

## কোর্স আউটলাইন 

### Part I: Neural Networks and Deep Learning
1. Embeddings, Latent Space, and Representations  
2. Self-Supervised Learning  
3. Few-Shot Learning  
4. The Lottery Ticket Hypothesis  
5. Reducing Overfitting with Data  
6. Reducing Overfitting with Model Modifications  
7. Multi-GPU Training Paradigms  
8. The Success of Transformers  
9. Generative AI Models  
10. Sources of Randomness  

---

### Part II: Computer Vision
11. Calculating the Number of Parameters  
12. Fully Connected and Convolutional Layers  
13. Large Training Sets for Vision Transformers  

---

### Part III: Natural Language Processing
14. The Distributional Hypothesis  
15. Data Augmentation for Text  
16. Self-Attention  
17. Encoder- and Decoder-Style Transformers  
18. Using and Fine-Tuning Pretrained Transformers  
19. Evaluating Generative Large Language Models  

---

### Part IV: Predictive Performance and Model Evaluation
20. Stateless and Stateful Training and Deployment  
21. Data-Centric AI vs. Model-Centric AI  
22. Speeding Up Inference  
23. Data Distribution Shifts  
24. Poisson and Ordinal Regression  
25. Confidence Intervals  
26. Conformal Prediction  
27. Proper Metrics  
28. The Cross-Entropy Loss  
29. Calibration  
30. Limited Labeled Data  

---

## কীভাবে শুরু করবেন
1. রিপোজিটরি ক্লোন করুন:
   - `git clone https://github.com/yourusername/ml-ai-course.git`
2. প্রতিটি চ্যাপ্টারের `notes.md` পড়ুন এবং `code.ipynb` রান করুন (Jupyter Notebook ব্যবহার করুন)
3. এক্সারসাইজ সমাধান করে Pull Request পাঠান
4. প্রশ্ন থাকলে Discussion সেকশনে পোস্ট করুন

---

## লাইসেন্স
**MIT License**

---

## কন্ট্রিবিউশন
Pull Request স্বাগত!  
নতুন উদাহরণ, ভুল সংশোধন, উন্নত ব্যাখ্যা, বা অনুবাদ—সব ধরনের অবদান গ্রহণযোগ্য।

---

## যোগাযোগ
- Email: `sakhawathossen912@gmail.com`  
